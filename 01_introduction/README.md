# 介绍

## 简介

1956 年提出 AI 概念，短短3年后（1959）[Arthur Samuel](https://en.wikipedia.org/wiki/Arthur_Samuel) 就提出了机器学习的概念：机器学习研究和构建的是一种特殊算法（而非某一个特定的算法），能够让计算机从经验数据中产生“模型”，基于模型对新的数据进行预测。机器学习的原理是把现实生活中解决问题的“经验”抽象成数学模型，并且很清楚模型中不同参数的作用。在本文中用“模型”泛指从数据中学得的结果。

AI 是目标，而机器学习 ML（Machine Learning）是实现 AI 的方法，它是计算机基于数据构建概率统计模型并运用模型对数据进行预测与分析的学科。ML 所研究的是关于在计算机上从经验数据中产生模型（model）的“学习算法”。有了“学习算法”，就可以把经验数据提供给它，它就能基于这些经验数据产生模型。在面对新的情况时，模型可以提供相应的判断。

### 数据科学 vs. AI

- 人工智能（AI）：通过机器模拟人类认知 – 感知、学习、推理、决策 
- 数据科学/挖掘：数据科学（Data Sciense） = 数据 + 科学，是从数据中获取信息的科学，其交叉领域包括计算机、统计及专业知识。它利用机器学习和统计学等技术，从大量数据中提取有效信息、模型。
- 机器学习
- 统计：数理统计和应用统计（描述统计、推论统计）

<img src="figures/image-20200306083537034.png" alt="image-20200306083537034" style="zoom:50%;" />

### 数据挖掘 vs. 机器学习

实际上数据挖掘和机器学习在很大程度上是重叠的。一些常用算法，比如 K-Means、KNN、SVM、决策树和朴素贝叶斯等，既可以说是数据挖掘算法，又可以说是机器学习算法。

- 数据挖掘：知识模型。数据挖掘通常是从现有的数据中提取规律模式（pattern）以及使用算法模型（model）。核心目的是找到这些数据变量之间的关系，因此也会通过数据可视化对变量之间的关系进行呈现，用算法模型挖掘变量之间的关联关系。通常情况下，我们只能判断出来变量 A 和变量 B 是有关系的，但并不一定清楚这两者之间有什么具体关系。在谈论数据挖掘的时候，更强调的是从数据中挖掘价值。
- 机器学习：经验模型。机器学习是人工智能的一部分，它指的是通过训练数据和算法模型让机器具有一定的智能。一般是通过已有的数据来学习经验，并通过各种算法模型形成一定的**处理能力**，比如分类、聚类、预测、推荐能力等。这样当有新的数据进来时，就可以通过训练好的模型对这些数据进行预测，也就是通过机器的智能帮我们完成某些特定的任务。

### 历史

- 第一次黄金期：1956 年 Dartmouth 会议，第一款神经网络软件 Perceptron，第一款人工智能软件 Logic Theorist 。
- 第二次黄金期：198 0年，第一次 AI 冬天，Hopfield 网络&BP 算法，第五代计算机兴起。第五代计算机失败，DARPA削减投入。2000年，第二次AI冬天。
- 第三次浪潮：深度学习（Hinton 2006），DNN 在语义识别上的成功，CNN 在图像上的成功。

<img src="figures/image-20200322170552314.png" alt="image-20200322170552314" style="zoom:50%;" />

### 五大流派

- 符号主义：使用符号、规则和逻辑来表征知识和进行逻辑推理，如规则和决策树
- 贝叶斯派：获取发生的可能性来进行概率推理，如朴素贝叶斯或马尔可夫
- 联结主义：使用概率矩阵和加权神经元来动态地识别和归纳模式，如神经网络
- 进化主义：生成变化，然后为特定目标获取其中最优的，如遗传算法
- Analogizer：根据约束条件来优化函数（尽可能走到更高，但同时不要离开道路），如支持向量机

### 判别式模型 vs. 生成式模型

机器学习的任务是从属性X预测标记Y，即求概率P(Y|X)：

- 判别式模型：知晓所有标签，返回最有可能的一个标签。它求得条件概率 P(Y|X)，对未见示例X，根据P(Y|X)可以求得标记Y，即可以直接判别出来。如图的左边所示，实际是就是直接得到了判别边界，所以传统的、耳熟能详的机器学习算法如线性回归模型、支持向量机SVM等都是判别式模型，这些模型的特点都是输入属性X可以直接得到Y（对于二分类任务来说，实际得到一个score，当score大于threshold时则为正类，否则为反类）。从另一个角度来说，判别式对于某示例 $x_1$，对正例和反例的标记的条件概率之和等于1，即 $P(y_1|x_1)+P(y_2|x_1)=1$。判别模型之所以称为“判别”，是因为其根据 X “判别” Y。
- 生成式模型：独立计算某几个标签的概率，然后做比较。它求得联合概率 P(Y,X)，对于未见示例 X，求出 X 与不同标记之间的联合概率分布，然后概率最大的获胜。如图右边所示，并没有什么边界存在，对于未见示例（红三角），求两个联合概率分布（有两个类），比较一下，取那个大的。机器学习中朴素贝叶斯模型、隐马尔可夫模型 HMM 等都是生成式模型。熟悉Naive Bayes的都知道，对于输入 X，需要求出好几个联合概率，然后较大的那个就是预测结果。也就是说，对于某示例$x_1$，对正例和反例的标记的联合概率之和不等于1，即$P(y_1,x_1)+P(y_2,x_1)<1$。要遍历所有的X和Y的联合概率求和，即 $\sum P(X,Y)=1$。生成模型之所以称为“生成”，是因为其预测的根据是联合概率P(X,Y)，而联合概率可以理解为“生成”(X,Y)样本的概率分布。 

<img src="figures/image-20210227164245059.png" alt="image-20210227164245059" style="zoom:30%;" />

举例来说，要确定一只羊是山羊还是绵羊。用判别模型的方法是从历史数据中学习到模型，然后通过提取这只羊的特征来预测出这只羊是山羊还是绵羊。利用生成模型是根据山羊的特征首先学习出一个山羊的模型，根据绵羊的特征学习出一个绵羊的模型，然后从这只羊中提取特征，分别放到山羊和绵羊的模型中做预测，然后比较哪个概率大。判别式模型是根据一只羊的特征可以直接给出这只羊是山羊的概率（比如logistic regression，这概率大于0.5时则为正例，否则为反例），而生成式模型是要都试一试，最大的概率的那个就是最后结果。

### 分类

模型训练方式不同可以分为监督学习（Supervised Learning），无监督学习（Unsupervised Learning）、半监督学习（Semi-supervised Learning）和强化学习（Reinforcement Learning）四大类。

#### 监督学习

基于已知类别的训练数据进行学习。监督学习假定训练数据满足独立同分布的条件，并根据训练数据学习出一个由输入到输出的映射模型。反映这一映射关系的模型可能有无数种，所有模型共同构成了假设空间。**监督学习的任务就是在假设空间中根据特定的误差准则找到最优的模型**。

- 分类（Classification）：就是通过训练集得到一个分类模型，然后用这个模型可以对其他数据进行分类。输出的是离散的值，当个数为 2 时即为最简单的二分类问题。
- - 集成学习：分类中的一种
- 回归（regression）：输出的是连续的值
- structure：输出的是类似于图形、语音等

#### 无监督学习

基于未知类别的训练数据进行学习

- 聚类：是利用算法进行自动归类。通过聚类分析可以发现事物的内在规律：具有相似购买习惯的用户群体被聚类为一组，一方面可以直接针对不同分组用户进行差别营销，根据分组情况进行市场划分；另一方面可以进一步分析，比如同组用户的其他统计特征还有哪些，并发现一些有价值的模式。
- 强化学习：最接近人类学习的办法。即，有 input，取代 label 的是 reward——不告诉你正确答案是什么，但是会根据你的答案表扬你或者批评你。

#### 半监督学习

同时使用已知类别和未知类别的训练数据进行学习

## 算法

### 三要素

- 样本：样本就是通常说的“训练数据”，包括输入和结果两部分。样本的数量和质量对机器学习的效果至关重要，如果样本量太少或样本分布不均衡，对训练出来的模型就有很大的影响。
- 模型：模型就是映射样本输入与样本结果的函数 f，可能是一个条件概率分布，也可能是一个决策函数。所有 f 的可能结果构成了模型的假设空间 H。很多时候 H 的函数类型是明确的，需要计算的是函数的参数，比如确定 f 函数为一个线性函数，那么 f 的函数表示就可以写为：$y=a_1 x+a_0$。
- 算法：算法就是要从模型的假设空间中寻找一个最优的函数，使得样本空间的输入 X 经过该函数的映射得到的 f(X)，和真实的 Y 值之间的距离最小。这个最优的函数通常没办法直接计算得到，即没有解析解，需要用数值计算的方法不断迭代求解。因此如何寻找到 f 函数的全局最优解，以及使寻找过程尽量高效，就构成了机器学习的算法。如何保证 f 函数的参数空间最接近最优解，就是算法的策略。机器学习中用损失函数来评估模型是否最接近最优解。损失函数用来计算模型预测值与真实值的差距，常用的有 0-1 损失函数、平方损失函数、绝对损失函数、对数损失函数等。

### 术语

#### 样本

- 样本（sample）/示例（instance）表示数据集中的每条数据。
- 特征（feature）/属性（attribute）：反映样本某方面性质的描述。被描述的性质叫作特征/属性，特征的取值称为特征值/属性值。
- 特征值（feature value）/属性值（attribute value）：特征上的取值。
- 特征空间（feature space）/属性空间（attribute space）/样本空间（sample space）：数据的不同特征之间可以视为相互独立，因而每个特征都代表了一个不同的维度，这些维度共同张成了特征空间。
- 特征向量（feature vector）：不同于线性代数中的“特征向量”，机器学习中的每个样本有 n 个特征值，这 n 个特征值组成的向量被称为特征向量，对应 n 维特征空间的一个点。因而**每个样本都可以视为特征空间中的一个向量**，即特征向量。
- 标记（label）：在监督学习下，样本已经打的标签。
- 标记空间（label space）/输出空间：所有标记的集合。
- 样例（example）：拥有标记的样本。

#### 数据集

- 数据集（data set）：一组样本的集合。
- 训练集（training set）：训练过程中使用的数据，相当于上课学知识，其中每个样本称为训练样本（training sample）。
- 验证集（validation set）：相当于课后的的练习题，用来纠正和强化学到的知识。模型选择与评估中用于评估测试的数据集称为“验证集”。例如不同神经网络在训练集上训练结束后，通过验证集来比较判断各个“学习算法”/模型的性能。这里的不同模型主要是指对应不同结构或超参数的神经网络。
- 测试集（testing set）：学得模型后，使用其进行测试的被预测样本称为测试样本（testing set）。相当于期末考试，用来最终评估学习效果。测试集应该尽量与训练集互斥，即测试样本尽量不在训练集中出现、为在训练过程中使用过。
- 误差（Error）：误差被定义为模型的实际预测输出与样本真实输出之间的差异。
  - 训练误差（training error）/经验误差（empirical error）：指学到的模型在训练数据集上的误差。训练误差描述的是输入属性与输出分类之间的相关性，能够判定给定的问题是不是一个容易学习的问题。
  - 测试误差（testing error）/泛化误差：指学到的模型在新的测试样本上的误差。测试误差反映了学到的模型对未知的测试数据集的预测能力，学习的目的是得到测试误差小的模型。
- 错误率：在分类问题中，分类错误的样本占全部样本的比例。

#### 学习

- 假设（hypothesis）：ML 训练学得的模型对应了关于训练数据的某种潜在的规律，因此称为假设。
- 假设空间（hypothesis space）：所有可能假设构成的集合，也就是后面训练时所说的model。
- 学习（learning）/训练（trianing）：从数据集中学得模型的过程。可以把 ML 看成在假设空间中搜索的过程，搜索的目的是找到与训练集“匹配（fit）”的假设。
- 泛化能力（generalization）：指学得的模型适用于新样本的能力，具有泛化能力的模型能很好地适用于整个样本空间。
- 版本空间（version space）：在实际问题中，常常会面临很大的假设空间，但学习的过程是基于有限样本训练集进行的，因此可能有多个假设与训练集一致，这些假设的集合被称为版本空间（version space）。
- 归纳偏好：归纳偏好表示在学习过程中对某一类假设的偏好，它可以看做是“学习算法”自身一个可能很庞大的假设空间中对假设进行选择的启发式“价值观”。
  - 奥卡姆剃刀（Occam's razor）：奥卡姆剃刀是一种归纳偏好，若在假设空间中有多个假设满足训练集，则选择最简单的那个。

### 过拟合/欠拟合

#### 欠拟合（underfitting）

如果说造成过拟合的原因是学习能力太强，造成欠拟合的原因就是学习能力太弱，以致于训练数据的基本性质都没能学到。

欠拟合的表现是：
- training error 大
- bias 大

解决方法：
- 增加训练轮数
- 说明模型过于简单，需要采用更复杂的模型

#### 过拟合（overfitting）

把训练数据的自身的一些特点错当做整体样本都会具有的一般性质，这样会导致泛化能力下降。例如，如果接触的外国人较少，从没见过双眼皮的韩国人，思维中就难免出现“单眼皮都是韩国人”的错误定式。过拟合出现的原因通常是学习时模型包含的参数过多，从而导致训练误差较低但测试误差较高。

过拟合的表现是：

- testing error 大
- variance大

解决方法是：
- 增加 training data：
- 调参 regularization：在 model 中加上一个 $w_{i}^2$

#### 偏差、方差、噪声

$E(f;D)=bias^2(x)+var(x)+\epsilon ^2$：泛化误差可以分解为偏差、方差和噪声之和。

- 偏差 bias：度量了学习算法的期望预测与真实结果的偏离程度，即刻画了学习算法本身的拟合能力。
- 方差 variance：度量了同样大小的训练集的变动所导致的学习性能的变化，即刻画了数据扰动造成的影响。
- 噪声：表达了在当前任务上任何学习算法所能达到的期望泛化误差的下线，即刻画了学习问题本身的难度。

偏差与方差是有冲突的，在训练不足时，模型的拟合能力不够强，训练数据的扰动不足以使模型产生显著变化，此时偏差主导了泛化误差。随着训练程度的加深，模型的拟合能力逐渐增强，训练数据扰动渐渐能被模型学到，因此方差主导了泛化误差。也就是，训练数据发生轻微的扰动都会导致模型的显著变化，训练数据自身的特性被模型学到了，将发生过拟合。

<img src="figures/image-20201115093120102.png" alt="image-20201115093120102" style="zoom: 15%;" />

## 标准流程

![image-20200306084839234](figures/image-20200306084839234.png)

### 业务知识

#### 问题定义

- 询问
  - 主要的目标
  - 量化决策，短期目标 v.s 长期增长
  - 好的指标：对齐目标, 可比较, 准确, 可执行
- 理解
  - 如何衡量成功? SMART，具体、可衡 量、时间限制
  - 列出假设、限制、重要因子
  - 研究现有方案
- 翻译
  - 业务目标 -> 技术目标
  - 调研相关成功案例
  - 技术选型；不同技术就像工具箱

<img src="figures/image-20200306085623871.png" alt="image-20200306085623871" style="zoom:50%;" />

#### 平台选型

选择语言/软件/工具

- Python, R, Spark, SPSS, SAS

#### 项目计划

- 时间
- 可用资源
- 工具和技术
- 风险和收益
- 项目里程碑（Milestones）


![image-20200306085917548](figures/image-20200306085917548.png)

### 特征工程

见“基础/特征工程”篇

### 建模预测

从假设空间中寻找一个最优的模型（函数），使得样本空间的输入 X 经过该函数的映射得到的 f(X) 与真实的 Y 值之间的距离最小。这个最优的函数通常没办法直接计算得到，需要用数值计算的方法不断迭代求解。因此如何寻找 f  函数的全局最优解，以及使寻找过程尽量高效，就构成了机器学习的算法。

完整的训练过程归结为一下两个步骤：

1. 预设“学习算法”的超级参数：
2. 训练模型的普通参数：基于“学习算法”给定超参数，在训练集上利用“学习算法”训练普通参数，使得模型在训练集上的误差降低到可接受的程度，从而获得最优模型（best function）。
3. 训练超参数：在验证集上验证“学习算法”的泛化能力，并根据模型性能对超参数进行调整

以上 2、3 两步循环执行，直至“学习算法”的超级参数在验证集上取得较低的泛化误差，此时完整的训练过程结束。在完成模型参数和“学习算法”超参数的训练后，在测试集上测试所得的最优模型（best function）的性能.

#### 学习算法确定
对于训练，有多个“学习算法”可以选择（也可以被称为通用模型），对于同一类“学习算法”，也有多种结构、“超级参数”可以选择。当使用不同的“超级参数”配置时，也会产生不同的“学习算法”。最正常的做法应当先使用验证集来调整“学习算法”的“超级参数”，再使用训练集来学习模型。当在验证集上取得最优的模型时，此时就可以使用此模型的超参数来重新训练（训练集+验证集），并用测试集评估最终的性能。

“学习算法”的调参除了对模型进行选择外，还需要对“学习算法”的“超级参数”进行设定，可以基于验证集（validation set）对特定参数的“学习算法”训练出的模型进行评估。例如，选择“深度神经网络”作为“学习算法”（通用模型），而 DNN 的层数以及每层的 neuron 数就是该“学习算法”的超级参数。

#### 模型训练

这步是在“学习算法选择”确定了“学习算法”结构及其“超级参数”之后，使用该“学习算法”训练具体的模型。

#### 模型评估选择

对于同一个“学习算法”，可能会产生不同的模型，理想的选择方式是对模型的泛化误差进行评估，然后选择泛化误差最小的那个模型。解决方法是通过实验测试来对模型的泛化误差进行评估、选择。具体操作是选择一个测试集来测试模型对新样本的判别能力，然后以测试集上的测试误差作为泛化误差的近似。关于训练集、测试集的划分，详见“特征工程”。

在模板评估与选择中用到的数据集被称为验证数据集（Validation Set），基于验证数据集上的性能来进行模型的评估与选择。

##### 模型性能度量

对模型的泛化性能进行评估，需要有衡量泛化能力的评价标准，也就是性能度量。评估的指标主要有准确率、召回率、F值，这个过程可以看到模型如何对尚未看到的数是如何做预测的，这意味着代表模型在现实世界中的表现。主要的性能度量包括：

- 错误率、精度：常用于分类算法，错误率是分类错误样本数占样本总数的比例，精度则是分类正确样本数占样本总数的比例。
- 查准率、查全率、F1：
- ROC（Receiver Operating Characteristic）：
- AUC（Area Under ROC Curve）：

##### 损失函数

通常通过损失函数（goodness function）对候选模型的性能（测试误差/泛化误差）进行评估，然后选择泛化误差最小的那个作为最优模型（best function）。

确定模型的损失函数，用来判断这个模型的效果，主要是为了看模型输出的结果跟真实结果的差别，差别越小效果越好。

##### 最优模型

根据损失函数计算得出在假设空间中的最优模型，**这也是整个机器学习中的核心工作**。

<img src="figures/image-20201115185232674.png" alt="image-20201115185232674" style="zoom:25%;" />

#### 学习算法/模型优化

完成模型选择和数后，存在 training error 或 validation error 过大，需要进一步改进获得的具体模型。

- 过拟合和欠拟合：统计学的Bias – Variance Trade Off ![image-20200306094057462](figures/image-20200306094057462.png)
- 训练集和测试集误差都大-> 欠拟合
  - 模型太简单或缺少关键特征
- 训练集误差小而测试集误差大->过拟合
  - 收集更多数据
  - 降低模型的复杂度方向调整模型超参数

改进：

- 调整学习算法 ：调整结构或超级参数
- 调整损失函数：

#### 评估反馈

- 模型应用：正式使用顺利所得的最优模型对测试数据集进行预测
- 评估结果：
  - 预测准确性
  - 可解释性
  - 运行时间
  - 部署难度

#### 数据可视化

- 结果展示
  - 效果指数
    - 离线指标：准确率、AUC、RMSE、Lift Chart
    - 在线指标：参与人数、ARPU、总收入、在线时长
  - 解释结果
    - 比较现有模型/业务规则
    - 影响因子重要性
    - 每个因子跟目标Y的关系
- 可视化展示

<img src="figures/image-20200306093634401.png" alt="image-20200306093634401" style="zoom:40%;" />

### 工程实现

#### 模型部署

- 输出形式
- 技术文档
- 模型复用

#### 监控维护

- 效果监控
  - 随着时间效果是否衰减
  - 预测值分布的变化
- 维护
  - 模型维护计划
  - 增加新数据源
  - 版本更新
- 测试
  - 测试计划和执行
  - 实验设计：A/B Test、Fractional Factorial

## 学习计划

### 不同角色

- 数据科学家：算法使用者
- 数据工程师：算法开发者
- 业务需求方：

### 数据科学家必备技能

- 数学统计：
  - 传统统计模型
  - 贝叶斯统计
  - 抽样调查
  - 实验设计
  - 机器学习
- 计算机编程：
  - 基本计算机知识
  - 数据库查询SQL
  - 并行计算
  - 大数据解决方案，如Hadoop、Spark等
  - Python或R编程语言
- 软实力：
  - 好奇心
  - 创造力
  - 业务领域知识
  - 终身学习能力
- 结果交流展示：
  - 自动化报表
  - 客户化展现
  - 交流能力
  - 将信息转化为具体行动建议

### 通用

对于想要以数据科学家-ML的身份进行应用机器学习的人，在没有博士学位的情况下，还有更多的东西：

- 分布式数据处理/机器学习：掌握Apache Spark，Apache Hadoop，Dask等技术的动手经验可以帮助您证明可以大规模创建数据/ ML管道。 与任何人都有经验应该是不错的选择，但是我还是建议使用Apache Spark（使用Python或Scala）。
- 生产ML /数据管道：如果您可以亲身体验Apache Airflow，这是一种用于创建数据和机器学习管道的标准开源作业编排工具。 目前，该行业已在使用它，因此建议您学习并围绕它进行一些项目。
- 数据库：必须了解数据库和查询语言。 尽管SQL非常被忽略，但是无论在任何云平台或数据库上，它仍然是行业标准。 开始在leetcode上练习复杂的SQL，这将帮助您完成DS概要文件中的部分编码采访，因为您将负责使用正在进行的预处理从仓库中导入数据，这将简化您在运行前进行预处理的工作 ML模型。 大多数功能工程可以在通过SQL将数据传输到模型中的同时进行，这是许多人忽略的一个方面。
- 编程语言：推荐用于数据科学的编程语言是Python、R、Scala 和 Java。了解他们中的任何一个都可以，并且可以解决问题。 对于ML类型的角色，面试过程中将进行现场编码回合，因此您需要在任何舒适的地方练习-Leetcode，Hackerrank或您喜欢的任何东西。

## Ref

1. [一口气读完人工智能简史](https://www.toutiao.com/a6761213894112313860/?tt_from=weixin&utm_campaign=client_share&wxshare_count=1&timestamp=1581728608&app=news_article&utm_source=weixin&utm_medium=toutiao_ios&req_id=202002150903280101290480370E50AAE1&group_id=6761213894112313860)
2. [陆奇最新演讲：没有学习能力，看再多世界也没用](https://page.om.qq.com/page/O-AOlyQhshJ7QZ9X9g1wq0ZA0)
3. 