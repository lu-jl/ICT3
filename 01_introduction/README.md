# 介绍

## 简介

1956 年提出 AI 概念，短短3年后（1959）[Arthur Samuel](https://en.wikipedia.org/wiki/Arthur_Samuel) 就提出了机器学习的概念：机器学习研究和构建的是一种特殊算法（而非某一个特定的算法），能够让计算机自己在数据中学习从而进行预测。机器学习的原理是把现实生活中的问题抽象成数学模型，并且很清楚模型中不同参数的作用。利用数学方法对这个数学模型进行求解，从而解决现实生活中的问题。

AI 是目标，而机器学习 ML（Machine Learning）是实现 AI 的方法，它是计算机基于数据构建概率统计模型并运用模型对数据进行预测与分析的学科。ML 所研究的是关于在计算机上从经验数据中产生模型（model）的“学习算法”。有了“学习算法”，就可以把经验数据提供给它，它就能基于这些经验数据产生模型。在面对新的情况时，模型可以提供相应的判断。



### 历史

- 第一次黄金期：1956年Dartmouth会议，第一款神经网络软件Perceptron，第一款人工智能软件Logic Theorist 。
- 第二次黄金期：1980年，第一次AI冬天，Hopfield网络&BP算法，第五代计算机兴起。第五代计算机失败，DARPA削减投入。2000年，第二次AI冬天。
- 第三次浪潮：深度学习(Hinton 2006)，DNN在语义识别上的成功，CNN在图像上的成功。

<img src="figures/image-20200322170552314.png" alt="image-20200322170552314" style="zoom:50%;" />

### 三要素

- 样本：样本就是通常说的“训练数据”，包括输入和结果两部分。样本的数量和质量对机器学习的效果至关重要，如果样本量太少，或者样本分布不均衡，对训练出来的模型就有很大的影响。
- 模型：模型就是映射样本输入与样本结果的函数 f，可能是一个条件概率分布，也可能是一个决策函数。所有 f 的可能结果构成了模型的假设空间 F。很多时候 F 的函数类型是明确的，需要计算的是函数的参数，比如确定 f 函数为一个线性函数，那么 f 的函数表示就可以写为：y=a1 x+a0
- 算法：算法就是要从模型的假设空间中寻找一个最优的函数，使得样本空间的输入 X 经过该函数的映射得到的 f(X)，和真实的 Y  值之间的距离最小。这个最优的函数通常没办法直接计算得到，即没有解析解，需要用数值计算的方法不断迭代求解。因此如何寻找到 f  函数的全局最优解，以及使寻找过程尽量高效，就构成了机器学习的算法。如何保证 f 函数或者 f 函数的参数空间最接近最优解，就是算法的策略。机器学习中用损失函数来评估模型是否最接近最优解。损失函数用来计算模型预测值与真实值的差距，常用的有 0-1 损失函数、平方损失函数、绝对损失函数、对数损失函数等。

### 术语

#### 样本

样本（sample）/示例（instance），表示数据集中的每条数据。

- 特征（feature）/属性（attribute）：反映样本某方面性质的描述。被描述的性质叫作特征/属性，特征的取值称为特征值/属性值。
- 特征空间（feature space）/属性空间（attribute space）/样本空间（sample space）/：数据的不同属性之间可以视为相互独立，因而每个属性都代表了一个不同的维度，这些维度共同张成了特征空间。
- 特征向量（feature vector）：不同于线性代数中的“特征向量”，机器学习中的每个数据有 n 个特征值，这 n 个特征值组成的向量被称为特征向量，对应 n 维特征空间的一个点。因而**每个样本都可以视为特征空间中的一个向量**，即特征向量。
- 标记（label）：监督学习下，样本已经打的标签
- 标记空间（label space）/输出空间：所有标记的集合
- 样例（example）：拥有标记的样本

#### 数据集

数据集（data set）是一组样本的集合。

- 训练集（training set）：训练过程中使用的数据，相当于上课学知识。其中每个样本称为训练样本。
- 验证集（validation set）：相当于课后的的练习题，用来纠正和强化学到的知识。模型选择与评估中用于评估测试的数据集称为“验证集”。例如不同神经网络在训练集上训练结束后，通过验证集来比较判断各个“学习算法”/模型的性能。这里的不同模型主要是指对应不同结构或超参数的神经网络。
- 测试集（testing set）：相当于期末考试，用来最终评估学习效果。学得模型后，使用其进行测试的被预测样本称为测试样本。测试集应该尽量与训练集互斥，即测试样本尽量不在训练集中出现、为在训练过程中使用过。
- 误差（Error）：误差被定义为学习器的实际预测输出与样本真实输出之间的差异。在分类问题中，常用的误差函数是错误率，即分类错误的样本占全部样本的比例。
  - 训练误差（training error）/经验误差（empirical error）：指的是学习器在训练数据集上的误差，也称经验误差。训练误差描述的是输入属性与输出分类之间的相关性，能够判定给定的问题是不是一个容易学习的问题。
  - 测试误差（testing error）：指的是学到的模型在新样本上的误差，也称泛化误差。测试误差反映了学到的模型对未知的测试数据集的预测能力。

#### 假设

假设（hypothesis）：ML 训练学得的模型对应了关于经验数据的某种潜在的规律，因此称为假设。

- 假设空间（hypothesis space）：所有可能函数构成的集合，也就是后面训练时所说的model。
- 泛化能力（generalization）：泛化能力只学得的模型适用于新样本的能力。具有泛化能力的模型能很好地适用于整个样本空间。

可以把 ML 看成在假设空间中搜索的过程，搜索的目的是找到与训练集“匹配”的假设。在实际问题中，常常会面临很大的假设空间，但学习的过程是基于有限样本训练集进行的。因此可能有多个假设与训练集一致。归纳偏好表示在学习过程中对某一类假设的偏好，它可以看做是“学习算法”自身一个可能很庞大的假设空间中对假设进行选择的启发式“价值观”。

- 奥卡姆剃刀（Occam's razor）：若在假设空间中有多个假设满足训练集，则选择最简单的那个。
- 

#### 过拟合 vs. 欠拟合

##### 欠拟合（underfitting）

如果说造成过拟合的原因是学习能力太强，造成欠拟合的原因就是学习能力太弱，以致于训练数据的基本性质都没能学到。

欠拟合的表现：

- training error 大
- bias 大

解决方法：

- 增加训练轮数
- 说明 model 过于简单，需要采用更复杂的 model

##### 过拟合（overfitting）

把训练数据的特征错当做整体的特征。例如如果接触的外国人较少，从没见过双眼皮的韩国人，思维中就难免出现“单眼皮都是韩国人”的错误定式。过拟合出现的原因通常是学习时模型包含的参数过多，从而导致训练误差较低但测试误差较高。

过拟合的表现是：

- testing error 大

- variance大

解决方法是：

- 增加 training data：
- 调参 regularization：在 model 中加上一个 w_{i}^2

<img src="figures/image-20201115093120102.png" alt="image-20201115093120102" style="zoom: 15%;" />

### 数据科学 vs. AI

- 人工智能（AI）：通过机器模拟人类认知 – 感知、学习、推理、决策 
- 数据科学/挖掘：数据科学（Data Sciense） = 数据 + 科学，是从数据中获取信息的科学，其交叉领域包括计算机、统计及专业知识。它利用机器学习和统计学等技术，从大量数据中提取有效信息、模型。
- 机器学习
- 统计：数理统计和应用统计（描述统计、推论统计）

<img src="figures/image-20200306083537034.png" alt="image-20200306083537034" style="zoom:50%;" />

#### 不同角色

- 数据科学家：算法使用者
- 数据工程师：算法开发者
- 业务需求方：

##### 数据科学家必备技能

- 数学统计：
  - 传统统计模型
  - 贝叶斯统计
  - 抽样调查
  - 实验设计
  - 机器学习
- 计算机编程：
  - 基本计算机知识
  - 数据库查询SQL
  - 并行计算
  - 大数据解决方案，如Hadoop、Spark等
  - Python或R编程语言
- 软实力：
  - 好奇心
  - 创造力
  - 业务领域知识
  - 终身学习能力
- 结果交流展示：
  - 自动化报表
  - 客户化展现
  - 交流能力
  - 将信息转化为具体行动建议

## 分类

模型训练方式不同可以分为监督学习（Supervised Learning），无监督学习（Unsupervised Learning）、半监督学习（Semi-supervised Learning）和强化学习（Reinforcement Learning）四大类。

### 监督学习

基于已知类别的训练数据进行学习。监督学习假定训练数据满足独立同分布的条件，并根据训练数据学习出一个由输入到输出的映射模型。反映这一映射关系的模型可能有无数种，所有模型共同构成了假设空间。**监督学习的任务就是在假设空间中根据特定的误差准则找到最优的模型**。

- 分类 Classification：输出的是离散的值，当个数为 2 时即为最简单的二分类问题。
- 回归 regression：输出的是连续的值
- structure：输出的是类似于图形、语音等

### 无监督学习

基于未知类别的训练数据进行学习

### 半监督学习

同时使用已知类别和未知类别的训练数据进行学习

### 强化学习

最接近人类学习的办法。即，有 input，取代 label 的是 reward——不告诉你正确答案是什么，但是会根据你的答案表扬你或者批评你。

### 集成学习

## 标准流程

![image-20200306084839234](figures/image-20200306084839234.png)

### 业务知识

#### 问题定义

- 询问
  - 主要的目标
  - 量化决策，短期目标 v.s 长期增长
  - 好的指标：对齐目标, 可比较, 准确, 可执行
- 理解
  - 如何衡量成功? SMART，具体、可衡 量、时间限制
  - 列出假设、限制、重要因子
  - 研究现有方案
- 翻译
  - 业务目标 -> 技术目标
  - 调研相关成功案例
  - 技术选型；不同技术就像工具箱

<img src="figures/image-20200306085623871.png" alt="image-20200306085623871" style="zoom:50%;" />

#### 平台选型

选择语言/软件/工具

- Python, R, Spark, SPSS, SAS

#### 项目计划

- 时间
- 可用资源
- 工具和技术
- 风险和收益
- 项目里程碑（Milestones）


![image-20200306085917548](figures/image-20200306085917548.png)

### 特征工程

见“基础/特征工程”篇

### 机器学习

#### 模型训练

从 model（假设空间）中寻找一个最优的函数，使得样本空间的输入 X 经过该函数的映射得到的 f(X) 与真实的 Y 值之间的距离最小。这个最优的函数通常没办法直接计算得到，需要用数值计算的方法不断迭代求解。因此如何寻找 f  函数的全局最优解，以及使寻找过程尽量高效，就构成了机器学习的算法。

完整的训练过程归结为一下两个步骤：

1. 预设“学习算法”超参数
2. 训练普通参数：在训练集（给定超参数）上利用学习算法训练普通参数，使得模型在训练集上的误差降低到可接受的程度，从而获得 best function。
3. 训练超参数：在验证集上验证“学习算法”的泛化能力，并根据模型性能对超参数进行调整

以上2、3两步循环执行，直至“学习算法”在验证集上取得较低的泛化误差，此时完整的训练过程结束。在完成参数和超参数的训练后，在测试集上测试 best function 的性能.

<<<<<<< HEAD
##### 学习算法选择&调参
=======
#### 通用模型选择
>>>>>>> fa6db09dfb63dcb75aa8bc74a2a3fb72059e6b36

对于训练，有多个“学习算法”可以选择（也可以被称为通用模型），对于同一个“通用模型”，

- “学习算法”结构选择：也就是对“学习算法”结构的选择。

#### 超级参数设置

当使用不同的“超级”参数配置时，也会产生不同的模型（一个模型就是整体假设空间中一类 function 的集合），这就是“模型选择”。最正常的做法应当先使用验证集来调整超参数，再使用训练集来学习。当在验证集上取得最优的模型时，此时就可以使用此模型的超参数来重新训练（训练集+验证集），并用测试集评估最终的性能。

- “学习算法”调参：除了对模型进行选择外，还需要对“学习算法”的参数进行设定，也就是调参。可以用验证集（validation set）对特定参数的“学习算法”训练出的模型进行评估。

例如，选择“深度神经网络”作为“学习算法”（通用模型），而 DNN 的层数以及每层的 neuron 数就是该“学习算法”的超级参数。

##### 算法模型训练

这步是在“学习算法选择”确定了“学习算法”结构及超参数之后，使用该“学习算法”训练具体的模型（一个模型就是整体假设空间中一类 function 的集合）。理想的解决方法是通过后续讲的 goodness function 对候选模型的测试误差（泛化误差）进行评估，然后选择泛化误差最小的那个作为 best function。

###### Goodness function

确定集合的 lost function，用来判断这个模型的效果，主要是为了看模型输出的结果跟真实结果的差别，差别越小效果越好。goodness function主要用于衡量所得模型的泛化能力，其评价标准就是性能度量（performance function）。评估的指标主要有准确率、召回率、F值，这个过程可以看到模型如何对尚未看到的数是如何做预测的，这意味着代表模型在现实世界中的表现。主要的性能度量包括：

- 错误率&精度：分类常用
- 均方误差（mean squard error）

###### Best function

根据 lost function 算出在 model 中最好的 function，**这也是整个机器学习中的核心工作**。

<img src="figures/image-20201115185232674.png" alt="image-20201115185232674" style="zoom:25%;" />

##### 学习算法&模型改进

完成模型选择和数后，存在 training error 或 validation error 过大，需要进一步改进获得的具体模型。

- 过拟合和欠拟合：统计学的Bias – Variance Trade Off ![image-20200306094057462](figures/image-20200306094057462.png)
- 训练集和测试集误差都大-> 欠拟合
  - 模型太简单或缺少关键特征
- 训练集误差小而测试集误差大->过拟合
  - 收集更多数据
  - 降低模型的复杂度方向调整模型超参数

改进：

- 重新调整学习算法 ：调整结构或超参数
- 重新调整 loss function：

<<<<<<< HEAD
#### 评估反馈

- 模型应用：正式使用顺利所得的 best function 对 testing set 进行预测
- 评估结果：
  - 预测准确性
  - 可解释性
  - 运行时间
  - 部署难度

#### 数据可视化

- 结果展示
  - 效果指数
    - 离线指标：准确率、AUC、RMSE、Lift Chart
    - 在线指标：参与人数、ARPU、总收入、在线时长
  - 解释结果
    - 比较现有模型/业务规则
    - 影响因子重要性
    - 每个因子跟目标Y的关系
- 可视化展示

<img src="figures/image-20200306093634401.png" alt="image-20200306093634401" style="zoom:40%;" />

### 工程实现

#### 模型部署

- 输出形式
- 技术文档
- 模型复用

#### 监控维护

- 效果监控
  - 随着时间效果是否衰减
  - 预测值分布的变化
- 维护
  - 模型维护计划
  - 增加新数据源
  - 版本更新
- 测试
  - 测试计划和执行
  - 实验设计：A/B Test、Fractional Factorial

## 用途

### 分类

就是通过训练集得到一个分类模型，然后用这个模型可以对其他数据进行分类。

### 聚类

“聚类”是利用算法进行自动归类。通过聚类分析可以发现事物的内在规律：具有相似购买习惯的用户群体被聚类为一组，一方面可以直接针对不同分组用户进行差别营销，根据分组情况进行市场划分；另一方面可以进一步分析，比如同组用户的其他统计特征还有哪些，并发现一些有价值的模式。

### 预测

顾名思义，就是通过当前和历史数据来预测未来趋势，它可以更好地帮助我们识别机遇和风险。

### 关联分析

分析数据之间潜在的关联

### 推荐算法

常用的推荐算法有：基于人口统计的推荐、基于商品属性的推荐、基于用户的协同过滤推荐、基于商品的协同过滤推荐。

- 基于人口统计的推荐：根据用户的基本信息进行分类，然后将商品推荐给同类用户。在人口统计信息的基础上，根据用户浏览、购买信息和其他相关信息，进一步细化用户的分类信息，给用户贴上更多的标签，比如家庭成员、婚姻状况、居住地、学历、专业、工作等，即所谓的用户画像。根据用户画像进行更精细的推荐，并进一步把用户喜好当做标签完善用户画像，再利用更完善的用户画像进行推荐，如此不断迭代优化用户画像和推荐质量。
- 基于商品属性的推荐：将商品的属性进行分类，然后根据用户的历史行为进行推荐。但是基于商品属性的推荐需要对商品属性进行全面的分析和建模，难度相对也更大一点。在实践中，一种简单的做法是提取商品描述的关键词和商品的标签作为商品的属性。
- 基于用户的协同过滤推荐：根据用户的喜好进行用户分类，常用的就是 KNN 算法，寻找和当前用户喜好最相近的 K 个用户，然后根据这些用户的喜好为当前用户进行推荐。基于用户的协同过滤推荐和基于人口统计的推荐都是将用户分类后，根据同类用户的喜好为当前用户进行推荐。不同的是，基于人口统计的推荐仅仅根据用户的个人信息进行分类，分类的粒度比较大，准确性也较差；而基于用户的协同过滤推荐则根据用户历史喜好进行分类，能够更准确地反映用户的喜好类别，推荐效果也更好一点。
- 基于商品的协同过滤推荐：根据用户的喜好对商品进行分类，如果两个商品，喜欢它们的用户具有较高的重叠性，就认为它们的距离相近，划分为同类商品，然后进行推荐。商品的分类相对用户的分类更为稳定，通常情况下，商品的数目也少于用户的数目，因此使用基于商品的协同过滤推荐，计算量和复杂度小于基于用户的协同过滤推荐。

## 学习计划

对于想要以数据科学家-ML的身份进行应用机器学习的人，在没有博士学位的情况下，还有更多的东西：
=======
### 使用模型
>>>>>>> fa6db09dfb63dcb75aa8bc74a2a3fb72059e6b36

- 分布式数据处理/机器学习：掌握Apache Spark，Apache Hadoop，Dask等技术的动手经验可以帮助您证明可以大规模创建数据/ ML管道。 与任何人都有经验应该是不错的选择，但是我还是建议使用Apache Spark（使用Python或Scala）。
- 生产ML /数据管道：如果您可以亲身体验Apache Airflow，这是一种用于创建数据和机器学习管道的标准开源作业编排工具。 目前，该行业已在使用它，因此建议您学习并围绕它进行一些项目。
- 数据库：必须了解数据库和查询语言。 尽管SQL非常被忽略，但是无论在任何云平台或数据库上，它仍然是行业标准。 开始在leetcode上练习复杂的SQL，这将帮助您完成DS概要文件中的部分编码采访，因为您将负责使用正在进行的预处理从仓库中导入数据，这将简化您在运行前进行预处理的工作 ML模型。 大多数功能工程可以在通过SQL将数据传输到模型中的同时进行，这是许多人忽略的一个方面。
- 编程语言：推荐用于数据科学的编程语言是Python，R，Scala和Java。 了解他们中的任何一个都可以，并且可以解决问题。 对于ML类型的角色，面试过程中将进行现场编码回合，因此您需要在任何舒适的地方练习-Leetcode，Hackerrank或您喜欢的任何东西。

## Ref

1. [一口气读完人工智能简史](https://www.toutiao.com/a6761213894112313860/?tt_from=weixin&utm_campaign=client_share&wxshare_count=1&timestamp=1581728608&app=news_article&utm_source=weixin&utm_medium=toutiao_ios&req_id=202002150903280101290480370E50AAE1&group_id=6761213894112313860)
2. [陆奇最新演讲：没有学习能力，看再多世界也没用](https://page.om.qq.com/page/O-AOlyQhshJ7QZ9X9g1wq0ZA0)
3. 