# 数据拆分

## 组成

在模型训练过程中，当数据本身没有什么问题后，会将有标签的数据分为 3 部分：训练集 train_set（60%）、验证集 valid_set（20%）、测试集 test_set（20%），用于后面的训练、验证/评估、测试，这是为了保证训练效果而特意设置的。有时也将训练集+验证集合称为样本集，而以上三类合在一起也会被统称为数据集。

在实际的模型训练中，训练的结果对于训练集的拟合程度通常还是挺好的，但是对于训练集之外的数据的拟合程度通常就不那么令人满意了。因此通常并不会把所有的数据集都拿来训练，，而是分出一部分来（验证集：这一部分不参加训练）对训练集生成的模型及其参数进行验证，相对客观的判断这些参数对训练集之外的数据的符合程度。而测试集很好理解，其实就是完全不参与训练的数据，仅仅用来观测测试效果的数据。

在比赛中，测试集还会分为 public 和 private 两部分，public 的测试集会提供无标签信息的数据，而 private 的测试集则不会提供。

## 分拆策略

训练、验证集分拆的策略，多少作为训练集、多少作为验证集？

最好分拆后的验证集数据分布能与之前的测试集相同，有利于在测试中得到高分。

### 留出法

留出法（hold-out）一次性地将数据集分为训练集、测试集两个互斥的集合，一般测试集占数据集的65%-80%。在训练集上训练模型后，用测试集来评估测试误差，作为对泛化误差的估计。训练集和测试集的划分要尽可能保持数据分布的一致性。

单次采用留出法得到的估计结果不够稳定可靠，一般要采用若干次随机划分、重复进行试验评估后取平均值作为留出法的评估结果。

### 交叉验证法

交叉验证法（Cross Validation）主要用于模型训练，在给定的样本集中拿出大部分样本进行模型训练，留小部分样本用刚建立的模型进行验证，并求这小部分样本的验证性能。交叉验证的核心思想是把原始样本集进行分组，一部分做为训练集、另一部分做为验证集。首先用训练集对模型进行训练，再利用验证集来测试训练得到的模型，以此来做为评价模型的性能指标。在此基础上可以得到多组不同的训练集和验证集，某次训练集中的某样本在下次可能成为测试集中的样本，即所谓“交叉”。　

那么什么时候才需要交叉验证呢？交叉验证用在数据不是很充足的时候。比如在我日常项目里面，对于普通适中问题，如果数据样本量小于一万条，我们就会采用交叉验证来训练优化选择模型。如果样本大于一万条的话，我们一般随机的把数据分成三份，一份为训练集（Train Set），一份为验证集（Validation Set），最后一份为测试集（Test  Set）。用训练集来训练模型，用验证集来评估模型预测的好坏和选择模型及其对应的参数。把最终得到的模型再用于测试集，最终决定使用哪个模型以及对应参数。

用交叉验证的目的是为了得到可靠稳定的模型。例如 10 折交叉验证（10-fold cross validation），将样本集分成十份，轮流将其中 9 份做训练 1 份做验证，10 次的结果的均值作为对模型性能的估计。一般还需要进行多次 10 折交叉验证求均值，例如：10 次 10 折交叉验证，以求更精确一点。

#### 简单的交叉验证

简单的交叉验证，所谓的简单，是和其他交叉验证方法相对而言的。首先，随机地将样本数据分为两部分（比如：  70%的训练集，30%的验证集），然后用训练集来训练模型，在验证集上验证模型及参数。接着，再把样本打乱，重新选择训练集和验证集，继续训练数据和检验模型。最后，选择损失函数评估最优的模型和参数。　通过反复的交叉验证，用损失函数来度量得到的模型的好坏，最终可以得到一个较好的模型。

#### K 折法

K 折（K-fold）交叉验证法，将数据集划分为 K 个大小相似的互斥子集，每个子集都能尽可能保持分布的一致性。每次用 K-1 个子集作为训练集，余下的一个子集作为验证集，这样就获得 K 组训练/验证集。进行 K 次训练后，最终返回的结果是 K 个结果的均值作为损失函数评估的最优模型和参数。

#### 留一法

假设数据集包含 N 个样本，若令 K=N，则得到了交叉验证法的一个特例：留一法（LOO Leave-One-Out）。对于 N 个样本，每次选择 N-1 个样本来训练数据，留一个样本来验证模型预测的好坏。此方法主要用于样本量非常少的情况，比如 N 小于 50 时，一般采用留一交叉验证。留一法不受随机样本划分方式的影响，所以其评估结果往往被认为比较准确。然而当数据集比较大时，其计算开销会比较大。

如果只是对数据做一个初步的模型建立，不是要做深入分析的话，简单交叉验证就可以了。否则就用 K 折交叉验证。在样本量少的时候，可以使用 K 折交叉验证的特例留一交叉验证。

### 自助法

还有一种比较特殊的交叉验证方式，也是用于样本量少的时候。叫做自助法（Bootstrapping）。自助法直接以自助采样为基础，在包含了 m 个样本的数据集中，每次随机从数据集中挑选一个样本放入测试集，然后再将该样本放回数据集，使得该样本在下次采样时任可能被采到。这个过程重复 m 次后，就得到了包含 m 个样本的测试集，这就是自助采样。当然，这 m 个样本中很有可能有重复的样本数据。同时，用没有被采样到的样本做测试集，这样接着进行交叉验证。由于我们的训练集有重复数据，这会改变数据的分布，因而训练结果会有估计偏差，因此，此种方法不是很常用，除非数据量真的很少，比如小于20个。

数据集中有一部分样本会在训练集中出现多次，而另一部分样本则不会出现。通过自助采样，在数据集中约有 $36.8\%$ 的样本未出现在训练集，而这部分样本将作为测试集。

## 分层法

在哪一类数据集中按照之前的拆分策略进行拆分？

针对以下任何一种分拆方法，都可以配合使用分层法。任何一个分拆都不能代表整个数据集，划分会导致有偏差的结果。我们期望的方法是将实例按照其在整个数据集的相同比例分到各个划分中，即划分中的类别比例和整个数据集中的类别比例是一样的。上述做法称为分层采样法（Stratfication），是一种好的方法。分层法中的层其实指的就是划分类别。

we'll get similar target distribution over different faults. If we split data into four faults with stratification, the average of each false target values will be equal.

用于：

- 少数据集
- 不平均的数据集


## Lab

- [数据分拆](50_separation.ipynb)

## Ref

1. [交叉验证](https://baike.baidu.com/item/%E4%BA%A4%E5%8F%89%E9%AA%8C%E8%AF%81/8543100?fr=aladdin)
2. 

