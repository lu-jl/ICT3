# 数据拆分

## 组成

在监督学习训练中，当数据本身没有什么问题后，会将有标签的数据集分为3个份，训练集（60%）、测试集（20%）、验证集（20%），用于后面的训练、测试、验证和评估，以上三类合在一起也会被统称为数据集。。

在比赛中，除了上述三部分的有标签数据之外，还会有另一个用于评分的测试集（这边称为 LB-测试集），LB-测试集还会分为 public 和 private 两部分。

## 验证/LB-测试分拆策略

将验证集与“训练+测试集”数据分开的策略，在比赛中也可用于分拆数据集与 LB-测试集的策略。

### 随机分拆

按照行随机拆分，一般每行都是独立的。

### 按时间分拆

不能用未来数据预测现在

#### Moving Window



### 按ID分拆





## 测试分拆策略

训练、测试集分拆，最好与“验证分拆策略”相同

### 留出法

留出法（hold-out）一次性地将数据集分为训练集、测试集两个互斥的集合，一般测试集占数据集的65%-80%。在训练集上训练模型后，用测试集来评估测试误差，作为对泛化误差的估计。训练集和测试集的划分要尽可能保持数据分布的一致性。

单次采用留出法得到的估计结果不够稳定可靠，一般要采用若干次随机划分、重复进行试验评估后取平均值作为留出法的评估结果。

### 交叉验证法

交叉验证法（Cross Validation）

#### K 折法

K 折（K-fold）交叉验证法，将数据集划分为 k 个大小相似的互斥子集，每个子集都能尽可能保持分布的一致性。每次用 k-1 个子集作为训练集，余下的一个子集作为测试集，这样就获得 k 组训练/测试集。进行 k 次训练，最终返回的结果是 k 个结果的均值。

#### 留一法

假设数据集包含 m 个样本，若令 k=m，则得到了交叉验证法的一个特例：留一法（LOO Leave-One-Out）。留一法不受随机样本划分方式的影响，所以其评估结果往往被认为比较准确。然而当数据集比较大时，其计算开销会比较大。

### 分层法

任何一个分拆都不能代表整个数据集，划分会导致有偏差的结果。我们期望的方法是将实例按照其在整个数据集的相同比例分到各个划分中，即划分中的类别比例和整个数据集中的类别比例是一样的。上述做法称为分层采样法（Stratfication），是一种好的方法。

we'll get similar target distribution over different faults. If we split data into four faults with stratification, the average of each false target values will be equal.

用于：

- 少数据集
- 不平均的数据集

### 自助法

自助法（bootstrapping）直接以自助采样（bootstrap sampling）为基础，在包含了 m 个样本的数据集中，每次随机从数据集中挑选一个样本放入测试集，然后再将该样本放回数据集，使得该样本在下次采样时任可能被采到。这个过程重复 m 次后，就得到了包含 m 个样本的测试集，这就是自助采样。

数据集中有一部分样本会在训练集中出现多次，而另一部分样本则不会出现。通过自助采样，在数据集中约有 $36.8\%$ 的样本未出现在训练集，而这部分样本将作为测试集。

自助法在数据集较小、难以有效划分训练集、测试集时很有用，然而它改变了数据分布，会引入估计偏差。 



