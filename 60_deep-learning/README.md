# 深度学习

## 简介

神经网络是一个具有相互连接的节点的计算系统，其节点的工作方式更像是人脑中的神经元。这些神经元在它们之间进行处理并传递信息。每个神经网络都是一系列的算法，这些算法试图通过一个模拟人类大脑运作的过程来识别一组数据中的潜在关系。【1】当神经网络层数比较多的时候，称它们为深度学习神经网络。

<img src="figures/image-20201128172901532.png" alt="image-20201128172901532" style="zoom:50%;" />

### 历史

-	1958: Perceptron (linear model)
-	1969: Perceptron has limitation
-	1980s: Multi-layer perceptron: Do not have significant difference from DNN today
-	1986: Backpropagation: Usually more than 3 hidden layers is not helpful
-	1989: 1 hidden layer is “good enough”, why deep?
-	2006: RBM initialization
-	2009: GPU
-	2011: Start to be popular in speech recognition
-	2012: win ILSVRC image competition 
-	2015.2: Image recognition surpassing human-level performance 
-	2016.3: Alpha GO beats Lee Sedol
-	2016.10: Speech recognition system as good as humans

### 深度学习 vs.  传统机器学习

- 传统机器学习的特征提取主要依赖人工，针对特定简单任务的时候人工提取特征会简单有效，但是并不能通用。
- 深度学习的特征提取并不依靠人工，而是机器自动提取的。这也是为什么大家都说深度学习的可解释性很差，因为有时候深度学习虽然能有好的表现，但是我们并不知道他的原理是什么。

### 分类

- Supervised
- Unsupervised

![image-20200304144134862](figures/image-20200304144134862.png)



## 感知机

感知机（Perceptron）就是一个 neuron，是一种比较简单的二分类模型，它将输入特征分类为 +1、-1 两类。它是由 2 层组成，输入层接收外部信号后传递给输出层，输出层进行激活函数的处理得到分类。例如，二维平面上的点只有两个输入特征（横轴坐标和纵轴坐标），一条直线就可以分类。如果输入数据有更多维度的特征，那么就需要建立同样多维度的模型，高维度上的分类模型也被称为超平面。

### 模型

感知机模型如下：``f(x)=sign(w⋅x+b)``

其中 x 代表输入的特征空间向量，输出空间是{-1, +1}，w 为权值向量，b 叫作偏置，sign 是一个符号函数：<img src="../20_basic/10_supervised/figures/image-20200220134302690.png" alt="image-20200220134302690" style="zoom:25%;" />

w⋅x+b=0 为超平面的方程：当感知机输出为 +1 表示输入值在超平面的上方，当感知机输出为 -1 表示输入值在超平面的下方。训练感知机模型就是要计算出 w 和 b  的值，当有新的数据需要分类的时候，输入感知机模型就可以计算出 +1 或者 -1 从而进行分类。

### 损失函数

偏差之和就是感知机的损失函数：<img src="figures/image-20200220135847658.png" alt="image-20200220135847658" style="zoom: 25%;" />。其中 M 为误分类点集合，误分类点越少，损失函数的值越小；如果没有误分类点，损失函数值为 0。求模型的参数 w 和 b，就是求损失函数的极小值。

一般采用梯度下降法求损失函数极小值，实质上就是求导过程的数值计算方法。对于误分类点集合 M，损失函数 L(w,b) 变化的梯度，就是某个函数变量的变化引起的函数值的变化，根据感知机损失函数可知：<img src="figures/image-20200220140621576.png" alt="image-20200220140621576" style="zoom:20%;" />

使用梯度下降更新 w 和 b，不断迭代使损失函数 L(w,b) 不断减小，直到为 0，也就是没有误分类点。感知机算法的实现过程：

1. 选择初始值 w0、b0。
2. 在样本集合中选择样本数据 xiyi。
3. 如果 yi(w⋅xi+b)<0，表示 yi 为误分类点，那么 w=w+ηyixi、b=b+ηyi，在梯度方向校正 w 和 b。其中 η 为步长，步长选择要适当，步长太长会导致每次计算调整太大出现震荡；步长太短又会导致收敛速度慢、计算时间长。
4. 跳转回 2，直到样本集合中没有误分类点， 即全部样本数据 yi(w⋅xi+b)≥0。

## 神经网络

### 简介

人脑神经元可以通过感知机进行模拟，每个感知机相当于一个神经元，使用 sign 函数的感知机输出也是只有两个值，跟人脑神经元一样。

x1,x2,x3  相当于神经元的树突，实现信号的输入；sum()+b 及 sign 函数相当于神经元细胞，完成输入的计算；y  是神经元的输出。用数学形式表达的话是``y=sign(w1x1+w2x2+w3x3+b)``，它是感知机 y=sign(w⋅x+b)  向量展开形式。

<img src="figures/image-20201127202035308.png" alt="image-20201127202035308" style="zoom: 25%;" />

将感知机组成一层或者多层网络状结构，就构成了机器学习的神经网络（Neural Network）。在多层神经网络中，每一层都由多个感知机组成。将输入的特征向量 x 传递给第一层的每一个感知机，运算以后作为输出传递给下一层的每一个感知机，直到最后一层感知机产生最终的输出结果。这就是机器学习神经网络的实现过程，通过模拟人脑神经网络，利用样本数据训练每个感知机神经元的参数，在某些场景下得到的模型可以具有不可思议的效果。

<img src="figures/image-20201117192158802.png" alt="image-20201117192158802" style="zoom: 33%;" />

### 算法

使用梯度下降算法，利用样本数据，可以训练神经网络、计算每个感知机的 w 和 b 参数值。当所有的感知机参数都计算出来，神经网络也就训练出来了。

训练神经网络的时候采用一种**反向传播**的算法，针对每个样本，从最后一层，也就是输出层开始，利用样本结果使用梯度下降算法计算每个感知机的参数。然后以这些参数计算出来的结果作为倒数第二层的输出计算该层的参数。然后逐层倒推，反向传播，计算完所有感知机的参数。

#### 激活函数

为了解决非线性的分类或回归问题，激活函数（activation funciton）必须是非线性的函数，另外使用基于梯度的方式来训练模型，因此激活函数也必须是连续可导的。 

- 两层神经网络：当选择两层神经网络时，原始感知机的 sign 函数表现并不太好，更常用的是 sigmoid 函数。
- 两层以上的多层神经网络：对于两层以上的多层神经网络，ReLU 函数的效果更好一些。ReLU 函数表达式是：``y=max(x,0)``当 x 大于 0，输出 x；当 x 小于 0，输出 0。

#### Model

也就是 network structure，多少层、每层多少个 neuron

#### Lost Function

- 每个 lost：<img src="figures/image-20201117192957220.png" alt="image-20201117192957220" style="zoom:50%;" />
- total lost：<img src="figures/image-20201117193109062.png" alt="image-20201117193109062" style="zoom:50%;" />

#### Best Function

还是采用梯度下降法

后续会采用 backprogapation 来有效的算 ∂L∕∂w。

### BP 算法

BP 反向传播算法（Backpropagation Algorithm）的基本想法是：由信号正向传播和误差反向传播。它基于 output 层的误差建立一个反向的类似于 NN 的计算链路，从而计算出基于误差的每个 w 权重的调整。反向传播计算 lost function 的导数表达式，它是每一层之间从左到右的导数乘积，而每一层之间的权重梯度是对部分乘积的简单修改（“反向传播误差”）。BP 将误差分摊给各个层的所有单元，从而获得各层单元的误差信号，此误差信号作为修正各个单元权值的依据。只有在 5 层内的 NN 会使用 BP，5 层以上 BP 就很不理想了。

我们向网络提供数据，它产生一个输出，我们将输出与期望的输出进行比较(使用损失函数)，然后根据差异重新调整权重。然后重复此过程。权重的调整是通过一种称为随机梯度下降的非线性优化技术来实现的。

对于：z=x_1 w_1+x_2 w_2+b，有：∂l∕∂w = ∂z∕∂w * ∂l∕∂z

- forward pass：∂z∕∂w，值就是 x_1、x_2

<img src="figures/image-20201128112217528.png" alt="image-20201128112217528" style="zoom:30%;" />

- backward pass：∂l∕∂z = ∂l∕∂a * ∂a∕∂z，其中 ∂a∕∂z 为常数 σ′(z)，而 ∂l∕∂a 为下一层 BP 的输出值

<img src="figures/image-20201128112658271.png" alt="image-20201128112658271" style="zoom: 33%;" />



###Network Structure

神经网络中每个感知机的参数可以通过训练获得，也就是 w 和 b 可以计算得到，但是一个神经网络应该设置多少层，每层应该有多少个 neuron，这些参数必须要算法工程师设置，因此这些参数也被称为超级参数。超级参数如何设置目前还没有太好的方法，只能依赖算法工程师的经验和不断尝试去优化。

一个神经网络就是一个model（function set），需要去设计层数，每个层有多少个neuron等，是设计这个model。

#### FNN

FNN 前馈神经网络（Feedforward Neural Network）是一种最简单的神经网络，各神经元分层排列。每个神经元只与前一层的神经元相连，接收前一层的输出，并输出给下一层。由于从输入到输出的过程中不存在与模型自身的反馈连接，因此被称为“前馈”。

- 多层神经元网络：单层感知器只能学习线性可分离的模式，而多层感知器则可以学习数据之间的非线性的关系
- 每一层是全连接的：层中的每个神经元都与下一层中的所有其他神经元相连

<img src="figures/image-20201117192325475.png" alt="image-20201117192325475" style="zoom: 33%;" />



##### Multi-classifier

在最后的 output layer 实现 multi-classifier

<img src="10_supervised/figures/image-20201117192605743.png" alt="image-20201117192605743" style="zoom:50%;" />

##### 类型

- 多层感知机（multilayer perceptron，MLP）
- 自编码器
- 限制玻尔兹曼机
- CNN

#### CNN

卷积神经网络 CNN（Convolutional Neural Network）属于前馈神经网络，其特点是每层的神经元节点只响应前一层局部区域范围内的神经元（全连接网络中每个神经元节点则是响应前一层的全部节点）。在数学中，卷积是一个函数越过另一个函数时两个函数重叠多少的积分度量。

一个深度卷积神经网络模型，一般由若干卷积层叠加若干全连接层组成，中间包含各种的非线性操作、池化操作。卷积运算主要用于处理网格结构的数据，因此 CNN 天生对图像数据的分析与处理有着优势。简单地来理解，那就是 CNN 是利用滤波器（Filter）将相邻像素之间的轮廓过滤出来。

#### RNN

在传统的神经网络中，可以理解所有输入和输出都是独立的。RNN之所以称为循环，是因为它们对序列的每个元素执行相同的任务，并且输出取决于先前的计算。RNN的另一种解释：这些网络具有“记忆”，考虑了先前的信息。

<img src="figures/b861badee3b3428a9f948dbf8f38b2ad.png" alt="深度学习算法完整简介" style="zoom: 50%;" />

##### LSTM

最常用的RNN类型是LSTM，它比RNN更好地捕获（存储）长期依赖关系。

#### 递归神经网络

#### 自编码器

自编码器可在输出处恢复输入信号。它们内部有一个隐藏层。自编码器设计为无法将输入准确复制到输出，但是为了使误差最小化，网络被迫学习选择最重要的特征。

<img src="figures/image-20201128173947043.png" alt="image-20201128173947043" style="zoom:50%;" />

#### 深度信念网络和受限玻尔兹曼机器

#### GAN

GAN 生成对抗网络有两个部分：

- 生成器：学习生成可信的数据。生成的实例成为判别器的负面训练实例。
- 判别器：学会从数据中分辨出生成器的假数据。判别器对产生不可信结果的发生器进行惩罚。

建立 GAN 的第一步是识别所需的最终输出，并根据这些参数收集初始训练数据集。然后将这些数据随机化并输入到生成器中，直到获得生成输出的基本精度为止。然后，将生成的图像与原始概念的实际数据点一起馈入判别器。判别器对信息进行过滤，并返回0到1之间的概率来表示每个图像的真实性（1与真相关，0与假相关）。然后检查这些值是否成功，并不断重复，直到达到预期的结果。

<img src="figures/2a6398dbf25e47ecae300ca7a1f2b3e5.png" alt="深度学习算法完整简介" style="zoom:50%;" />

## 优化

### 训练集表现不佳

#### Adaptive Learning Rate

- Vanilla
- Adagrad
- RMSProp

#### New Activation Function

- ReLU
- Maxout

### 测试集表现不佳

#### Dropout

每次训练前先去掉一些用不到的 neuron

#### Regularization

在 lost funciton 上再加上一个 regularization term：<img src="figures/image-20201128113708480.png" alt="image-20201128113708480" style="zoom:33%;" />

#### Early Stopping



## Ref

1. [深度学习算法完整简介](https://www.toutiao.com/i6812916374394896910/?tt_from=weixin&utm_campaign=client_share&wxshare_count=1&timestamp=1602943120&app=news_article&utm_source=weixin&utm_medium=toutiao_ios&use_new_style=1&req_id=202010172158390100120640510F6549D8&group_id=6812916374394896910)












## 


